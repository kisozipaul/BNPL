{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ================== Patch AdvancedStacker for backward compatibility, restart & test ==================\n",
        "import os, time, json, requests, textwrap, sys, types\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"üîß Patching advanced_stacker.py with legacy-attribute compatibility...\")\n",
        "\n",
        "advanced_stacker_code = r'''\n",
        "import numpy as np\n",
        "from sklearn.base import BaseEstimator, RegressorMixin\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "class AdvancedStacker(BaseEstimator, RegressorMixin):\n",
        "    \"\"\"\n",
        "    Backward-compatible stacker that tolerates different internal attribute names\n",
        "    across training and inference (e.g., base_models_, models_, fitted_base_models).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, base_models=None, meta_model=None, cv_folds=5):\n",
        "        self.base_models = base_models if base_models else []\n",
        "        self.meta_model = meta_model if meta_model else Ridge(alpha=1.0)\n",
        "        self.cv_folds = cv_folds\n",
        "\n",
        "    # -------------------- legacy mapping helpers --------------------\n",
        "    _BASE_KEYS_CANDIDATES = (\n",
        "        \"base_models_\", \"models_\", \"fitted_base_models\", \"base_models_fitted_\",\n",
        "        \"estimators_\", \"estimators\", \"learners_\", \"learners\"\n",
        "    )\n",
        "\n",
        "    _META_KEYS_CANDIDATES = (\n",
        "        \"meta_model_\", \"meta_model\", \"meta_\", \"final_estimator_\", \"final_estimator\",\n",
        "        \"meta\", \"final_model_\", \"final_model\"\n",
        "    )\n",
        "\n",
        "    def _coerce_list(self, obj):\n",
        "        \"\"\"Coerce possible structures (dict, list of tuples) to a plain list of estimators.\"\"\"\n",
        "        if obj is None:\n",
        "            return None\n",
        "        # sklearn-like list of (name, estimator)\n",
        "        if isinstance(obj, (list, tuple)) and len(obj) > 0 and isinstance(obj[0], (list, tuple)) and len(obj[0]) == 2:\n",
        "            return [est for _, est in obj]\n",
        "        # dict of name->estimator\n",
        "        if isinstance(obj, dict):\n",
        "            return list(obj.values())\n",
        "        # already a list/tuple of estimators\n",
        "        if isinstance(obj, (list, tuple)):\n",
        "            return list(obj)\n",
        "        # single estimator\n",
        "        return [obj]\n",
        "\n",
        "    def _get_base_models_fitted(self):\n",
        "        # Preferred, if present\n",
        "        if hasattr(self, \"base_models_\") and getattr(self, \"base_models_\") is not None:\n",
        "            return self._coerce_list(getattr(self, \"base_models_\"))\n",
        "        # Try legacy keys\n",
        "        for key in self._BASE_KEYS_CANDIDATES:\n",
        "            if hasattr(self, key):\n",
        "                val = getattr(self, key)\n",
        "                if val is not None:\n",
        "                    return self._coerce_list(val)\n",
        "        # As a last resort, sometimes base_models (unfitted) were kept but actually contain fitted objects\n",
        "        if hasattr(self, \"base_models\") and self.base_models:\n",
        "            return self._coerce_list(self.base_models)\n",
        "        return None\n",
        "\n",
        "    def _get_meta_fitted(self):\n",
        "        # Preferred\n",
        "        if hasattr(self, \"meta_model_\") and getattr(self, \"meta_model_\") is not None:\n",
        "            return getattr(self, \"meta_model_\")\n",
        "        # Try legacy keys\n",
        "        for key in self._META_KEYS_CANDIDATES:\n",
        "            if hasattr(self, key):\n",
        "                val = getattr(self, key)\n",
        "                if val is not None:\n",
        "                    return val\n",
        "        # Fallback to declared meta_model (may already be fitted in pickle)\n",
        "        if hasattr(self, \"meta_model\") and self.meta_model is not None:\n",
        "            return self.meta_model\n",
        "        return None\n",
        "\n",
        "    def __setstate__(self, state):\n",
        "        \"\"\"\n",
        "        On unpickle, map legacy keys onto the modern ones if they exist.\n",
        "        \"\"\"\n",
        "        # Map possible legacy keys ‚Üí canonical names\n",
        "        mappings = {\n",
        "            \"models_\": \"base_models_\",\n",
        "            \"fitted_base_models\": \"base_models_\",\n",
        "            \"base_models_fitted_\": \"base_models_\",\n",
        "            \"estimators_\": \"base_models_\",\n",
        "            \"estimators\": \"base_models_\",\n",
        "            \"learners_\": \"base_models_\",\n",
        "            \"learners\": \"base_models_\",\n",
        "\n",
        "            \"meta\": \"meta_model_\",\n",
        "            \"meta_\": \"meta_model_\",\n",
        "            \"final_estimator_\": \"meta_model_\",\n",
        "            \"final_estimator\": \"meta_model_\",\n",
        "            \"final_model_\": \"meta_model_\",\n",
        "            \"final_model\": \"meta_model_\",\n",
        "        }\n",
        "        # Copy to avoid mutating while iterating\n",
        "        new_state = dict(state)\n",
        "        for old, new in mappings.items():\n",
        "            if old in new_state and new not in new_state:\n",
        "                new_state[new] = new_state[old]\n",
        "        self.__dict__.update(new_state)\n",
        "\n",
        "    # -------------------- standard API --------------------\n",
        "    def fit(self, X, y):\n",
        "        if not self.base_models:\n",
        "            self.base_models = [\n",
        "                RandomForestRegressor(n_estimators=100, random_state=42),\n",
        "                GradientBoostingRegressor(n_estimators=100, random_state=42),\n",
        "                Ridge(alpha=1.0)\n",
        "            ]\n",
        "        # Train base models\n",
        "        self.base_models_ = [m.fit(X, y) for m in self.base_models]\n",
        "        # Meta-features\n",
        "        meta_features = np.column_stack([m.predict(X) for m in self.base_models_])\n",
        "        # Train meta-model\n",
        "        self.meta_model_ = self.meta_model.fit(meta_features, y)\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        # Resolve fitted base models robustly\n",
        "        base_models_fitted = self._get_base_models_fitted()\n",
        "        if not base_models_fitted:\n",
        "            raise AttributeError(\"AdvancedStacker: no fitted base models found (base_models_)\")\n",
        "        # Build meta features\n",
        "        meta_features = np.column_stack([m.predict(X) for m in base_models_fitted])\n",
        "        # Resolve fitted meta\n",
        "        meta = self._get_meta_fitted()\n",
        "        if meta is None or not hasattr(meta, \"predict\"):\n",
        "            raise AttributeError(\"AdvancedStacker: no fitted meta model found (meta_model_)\")\n",
        "        return meta.predict(meta_features)\n",
        "\n",
        "    def get_params(self, deep=True):\n",
        "        return {'base_models': self.base_models, 'meta_model': self.meta_model, 'cv_folds': self.cv_folds}\n",
        "\n",
        "    def set_params(self, **params):\n",
        "        for k, v in params.items():\n",
        "            setattr(self, k, v)\n",
        "        return self\n",
        "'''\n",
        "\n",
        "Path(\"advanced_stacker.py\").write_text(advanced_stacker_code, encoding=\"utf-8\")\n",
        "print(\"‚úÖ advanced_stacker.py updated.\")\n",
        "\n",
        "# Restart uvicorn\n",
        "print(\"üîÅ Restarting FastAPI server...\")\n",
        "!pkill -f uvicorn 2>/dev/null || true\n",
        "!fuser -k 8000/tcp 2>/dev/null || true\n",
        "!nohup uvicorn main:app --host 0.0.0.0 --port 8000 > server.log 2>&1 &\n",
        "time.sleep(6)\n",
        "\n",
        "# Re-check health\n",
        "print(\"ü©∫ Checking /health ‚Ä¶\")\n",
        "r = requests.get(\"http://127.0.0.1:8000/health\", timeout=10)\n",
        "print(\"status:\", r.status_code)\n",
        "print(json.dumps(r.json(), indent=2))\n",
        "\n",
        "# Try a prediction again\n",
        "sample = {\n",
        "    \"timestamp\": \"2025-01-15T08:30:00\",\n",
        "    \"current_light\": \"Green\",\n",
        "    \"eta_to_light_s\": 45.5,\n",
        "    \"distance_to_next_light_m\": 200.0,\n",
        "    \"vehicle_count\": 3,\n",
        "    \"pedestrian_count\": 2,\n",
        "    \"lead_vehicle_speed_kmh\": 45.0,\n",
        "    \"speed_limit_kmh\": 50.0\n",
        "}\n",
        "resp = requests.post(\"http://127.0.0.1:8000/predict\", json=sample, timeout=15)\n",
        "print(\"\\nüîÆ /predict status:\", resp.status_code)\n",
        "print(\"content-type:\", resp.headers.get(\"content-type\"))\n",
        "print(\"body:\", textwrap.shorten(resp.text, width=800, placeholder=\"‚Ä¶\"))\n",
        "try:\n",
        "    print(\"json:\", resp.json())\n",
        "except Exception:\n",
        "    pass\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ig9oQ77WyLSn",
        "outputId": "569f1256-5bb8-4770-af0f-5bcbd50ae70f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîß Patching advanced_stacker.py with legacy-attribute compatibility...\n",
            "‚úÖ advanced_stacker.py updated.\n",
            "üîÅ Restarting FastAPI server...\n",
            "^C\n",
            "ü©∫ Checking /health ‚Ä¶\n",
            "status: 200\n",
            "{\n",
            "  \"status\": \"healthy\",\n",
            "  \"model_loaded\": true,\n",
            "  \"features_loaded\": true,\n",
            "  \"features_count\": 55,\n",
            "  \"message\": \"Ready\",\n",
            "  \"last_error\": null,\n",
            "  \"versions\": {\n",
            "    \"python\": \"3.12.12\",\n",
            "    \"numpy\": \"2.0.2\",\n",
            "    \"pandas\": \"2.2.2\",\n",
            "    \"joblib\": \"1.5.2\",\n",
            "    \"platform\": \"Linux-6.6.105+-x86_64-with-glibc2.35\"\n",
            "  }\n",
            "}\n",
            "\n",
            "üîÆ /predict status: 200\n",
            "content-type: application/json\n",
            "body: {\"prediction_id\":\"pred_1763047900\",\"seconds_to_next_change\":10.03,\"message\":\"Predicted 10.03 seconds until next light change\",\"features_used\":55}\n",
            "json: {'prediction_id': 'pred_1763047900', 'seconds_to_next_change': 10.03, 'message': 'Predicted 10.03 seconds until next light change', 'features_used': 55}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests, textwrap\n",
        "\n",
        "URL = \"http://127.0.0.1:8000/predict\"   # if you were hitting the Cloudflare URL, switch to localhost first\n",
        "payload = {\n",
        "    \"timestamp\": \"2025-11-13T15:45:00\",\n",
        "    \"current_light\": \"Green\",\n",
        "    \"eta_to_light_s\": 100.0,\n",
        "    \"distance_to_next_light_m\": 150.0,\n",
        "    \"vehicle_count\": 3,\n",
        "    \"pedestrian_count\": 1,\n",
        "    \"lead_vehicle_speed_kmh\": 42.0,\n",
        "    \"speed_limit_kmh\": 50.0\n",
        "}\n",
        "\n",
        "r = requests.post(URL, json=payload, timeout=15)\n",
        "\n",
        "print(\"status:\", r.status_code)\n",
        "print(\"content-type:\", r.headers.get(\"content-type\"))\n",
        "print(\"raw text (first 800 chars):\\n\", textwrap.shorten(r.text, width=800, placeholder=\"‚Ä¶\"))\n",
        "\n",
        "# Only call .json() if it actually looks like JSON\n",
        "if r.headers.get(\"content-type\",\"\").lower().startswith(\"application/json\"):\n",
        "    print(\"as json:\", r.json())\n",
        "else:\n",
        "    print(\"Not JSON; see raw text above.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4UGhYPhzcAs",
        "outputId": "90427186-fd79-4aee-b6d3-4ddce63be5f9"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "status: 200\n",
            "content-type: application/json\n",
            "raw text (first 800 chars):\n",
            " {\"prediction_id\":\"pred_1763047928\",\"seconds_to_next_change\":10.02,\"message\":\"Predicted 10.02 seconds until next light change\",\"features_used\":55}\n",
            "as json: {'prediction_id': 'pred_1763047928', 'seconds_to_next_change': 10.02, 'message': 'Predicted 10.02 seconds until next light change', 'features_used': 55}\n"
          ]
        }
      ]
    }
  ]
}